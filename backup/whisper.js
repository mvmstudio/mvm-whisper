import fs from "fs";
import dotenv from "dotenv";
import { OpenAI } from "openai";

dotenv.config();

// üîπ –£–∫–∞–∂–∏ –ø—É—Ç—å –¥–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
const BASE_NAME = "chunk_3";

const AUDIO_FILE_PATH = `chunks/${BASE_NAME}.mp3`; // –£–∫–∞–∂–∏ —Å–≤–æ–π –ø—É—Ç—å
const OUTPUT_FILE = `${BASE_NAME}.txt`; // –£–∫–∞–∂–∏ –∏–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞

// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI API
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

async function transcribeAudio() {
  try {
    // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
    if (!fs.existsSync(AUDIO_FILE_PATH)) {
      console.error("‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω!");
      return;
    }

    console.log("‚è≥ –û—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–∞–π–ª–∞ –Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é...");

    // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∞–π–ª –≤ OpenAI Whisper
    const response = await openai.audio.transcriptions.create({
      file: fs.createReadStream(AUDIO_FILE_PATH),
      model: "whisper-1",
      language: "en", // –ú–æ–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å —è–∑—ã–∫
      response_format: "verbose_json",
      timestamp_granularities: "segment"
    });

    const transcript = response.text;

    // –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–∞–π–ª
    fs.writeFileSync(OUTPUT_FILE, transcript, "utf8");

    console.log(`‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω –∫–∞–∫ ${OUTPUT_FILE}`);
  } catch (error) {
    console.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏:", error);
  }
}

// –ó–∞–ø—É—Å–∫ —Ñ—É–Ω–∫—Ü–∏–∏
transcribeAudio();
